{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing necessary libraries, we next import the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('C:\\\\Users\\\\Akshita Puri\\\\Desktop\\\\project\\\\dmpa\\\\mbti_1.csv')\n",
    "data=data.iloc[0:5000,:]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt_types=data['type'].value_counts()\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(cnt_types.index,cnt_types.values,alpha=0.8)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Types')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular function below is required to encode the personality type combinations into binary format. It is then applied to the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>IE</th>\n",
       "      <th>NS</th>\n",
       "      <th>TF</th>\n",
       "      <th>JP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  IE  NS  TF  JP\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   1   1   0   1\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...   0   1   1   0\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...   1   1   1   0\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   1   1   1   1\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...   0   1   1   1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_types(row):\n",
    "    t=row['type']\n",
    "    I=0;N=0\n",
    "    T=0;J=0\n",
    "    if(t[0]=='I'):\n",
    "        I=1\n",
    "    elif(t[0]=='E'):\n",
    "        I=0\n",
    "    else:\n",
    "        print('IE incorrect')\n",
    "    if(t[1]=='N'):\n",
    "        N=1\n",
    "    elif(t[1]=='S'):\n",
    "        N=0\n",
    "    else:\n",
    "        print('NS incorrect')\n",
    "        \n",
    "    if(t[2]=='T'):\n",
    "        T=1\n",
    "    elif(t[2]=='F'):\n",
    "        T=0\n",
    "    else:\n",
    "        print('TF incorrect')\n",
    "    if(t[3]=='J'):\n",
    "        J=1\n",
    "    elif(t[3]=='P'):\n",
    "        J=0\n",
    "    else:\n",
    "        print('JP incorrect')\n",
    "    \n",
    "    return pd.Series({'IE':I,'NS':N,'TF':T,'JP':J})\n",
    "\n",
    "data=data.join(data.apply(lambda row: get_types(row),axis=1))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple correlation matrix in order to remove if there are any dependent personality types. This is not a necessary step but useful in getting insight of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IE</th>\n",
       "      <th>NS</th>\n",
       "      <th>TF</th>\n",
       "      <th>JP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031347</td>\n",
       "      <td>-0.079885</td>\n",
       "      <td>0.169806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NS</th>\n",
       "      <td>-0.031347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.088525</td>\n",
       "      <td>0.020528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF</th>\n",
       "      <td>-0.079885</td>\n",
       "      <td>-0.088525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JP</th>\n",
       "      <td>0.169806</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>-0.020733</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IE        NS        TF        JP\n",
       "IE  1.000000 -0.031347 -0.079885  0.169806\n",
       "NS -0.031347  1.000000 -0.088525  0.020528\n",
       "TF -0.079885 -0.088525  1.000000 -0.020733\n",
       "JP  0.169806  0.020528 -0.020733  1.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['IE','NS','TF','JP']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 2 functions are used to retrieve the personality type from binary format and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_pers={'I':0,'E':1,'N':0,'S':1,'F':0,'T':1,'J':0,'P':1}\n",
    "b_persList=[{0:'I',1:'E'},{0:'N',1:'S'},{0:'F',1:'T'},{0:'J',1:'P'}]\n",
    "def translate_pers(personal):\n",
    "    return[b_pers[l] for l in personal]\n",
    "def translate_back(person):\n",
    "    s=\"\"\n",
    "    for i,l in enumerate(person):\n",
    "        s+=b_persList[i][l]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following python libraries are quitessential for sentiment analysis.\n",
    "PorterStemmer is used for stemming which implies that all the the words are converted to their root words in order to extravicate the same meaning. For eg: the root word for studied, studying and studies will be study.\n",
    "Stopwords are used to remove the short words like 'is','an','was' etc which particularly do not hold any context.\n",
    "Tokenize is to convert the text into a list of words without the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will also be dealing with tweets which involve content like emoticons, hastags,various non textual symbols, below is a function which takes care of removal of all such irrelvant information. Yes emoticons can be decoded as well and they may provide some information but they would have negligible reflection on personality.\n",
    "The re library handles all the regular expressions for removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_type_list=['infj','entp','intp','intj','entj','enfj','infp','enfp','isfp','istp','isfj','istj','estp','esfp','estj','esfj']\n",
    "stemmer=PorterStemmer()\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "sw=stopwords.words('english')\n",
    "def pre_process(data,remove_stop_words=True,remove_mbti_profiles=True):\n",
    "    personality=[]\n",
    "    post=[]\n",
    "    len_data=len(data)\n",
    "    i=0\n",
    "    \n",
    "    for row in data.iterrows():\n",
    "        pos=row[1].posts\n",
    "        temp=re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-@._&+]|(?:[0-9a-fA-F][0-9a-fA-F]))+',' ',pos)\n",
    "        temp=re.sub(\"^[a-zA-Z]\",\" \",temp)\n",
    "        temp=re.sub(' +',' ',temp).lower()\n",
    "        if remove_stop_words:\n",
    "            temp=\" \".join([lemmatizer.lemmatize(w) for w in temp.split(' ') if w not in sw])\n",
    "        else:\n",
    "            temp=\" \".join([lemmatizer.lemmatize(w) for w in temp.split(' ')])\n",
    "        \n",
    "        \n",
    "                \n",
    "        type_labelized=translate_pers(row[1].type)\n",
    "        personality.append(type_labelized)\n",
    "        post.append(temp)\n",
    "    post=np.array(post)\n",
    "    personality=np.array(personality)\n",
    "    return post,personality\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_posts,list_personality=pre_process(data,remove_stop_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-Idf is an important concept when dealing with textual data. It has some simple math behind it but the utility is, in simple words, to obtain words which are low in frequency ie the ones which provide the context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=CountVectorizer(analyzer=\"word\",max_features=1500,tokenizer=None,max_df=0.7,min_df=0.1)\n",
    "x_cnt=counter.fit_transform(list_posts)\n",
    "tf=TfidfTransformer()\n",
    "x_tfidf=tf.fit_transform(x_cnt).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(enumerate(counter.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_indicators=[\"IE:Introversion(I)/Extroversion(E)\",\"NS:Intuition(N)-Sensing(S)\",\"FT:Feeling(F)-Thinking(T)\",\"JP:Judging(J)-Perceiving(P)\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we have worked on is that using XGboost which is derived from Gradient Boost.\n",
    "Gradient boost has a lot of depth to it but as of now we have used it for classification. Here,in XGBoost, a number of classification trees are built with parameters like learning rate and regularization added to simple gradient boost which need to be tuned to obtain optimum results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be trained from the training set imported earlier and then it will be used to predict the personality type of a user from Twitter using their tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting below, we have illustrated how we keep adding paramters to our model in order to build it.\n",
    "First, we started with basic XGBoostClassifier and obtained an accuracy score via testing on 20% of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE:Introversion(I)/Extroversion(E) ....\n",
      "84.72727272727273\n",
      "NS:Intuition(N)-Sensing(S) ....\n",
      "90.24242424242425\n",
      "FT:Feeling(F)-Thinking(T) ....\n",
      "83.75757575757575\n",
      "JP:Judging(J)-Perceiving(P) ....\n",
      "80.36363636363636\n"
     ]
    }
   ],
   "source": [
    "X=x_tfidf\n",
    "acc=[]\n",
    "for l in range(len(type_indicators)):\n",
    "    print(type_indicators[l],'....')\n",
    "    Y=list_personality[:,l]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.33,random_state=42)\n",
    "    model=XGBClassifier()\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    predictions=[round(value) for value in y_pred]\n",
    "    accuracy=accuracy_score(y_test,predictions)\n",
    "    \n",
    "    print(accuracy*100.0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we added a few more parameters to increase the learning efficiency of the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE:Introversion(I)/Extroversion(E) ....\n",
      "[0]\tvalidation_0-logloss:0.56550\n",
      "Will train until validation_0-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.49741\n",
      "[2]\tvalidation_0-logloss:0.45314\n",
      "[3]\tvalidation_0-logloss:0.42912\n",
      "[4]\tvalidation_0-logloss:0.41004\n",
      "[5]\tvalidation_0-logloss:0.39831\n",
      "[6]\tvalidation_0-logloss:0.38906\n",
      "[7]\tvalidation_0-logloss:0.37488\n",
      "[8]\tvalidation_0-logloss:0.36990\n",
      "[9]\tvalidation_0-logloss:0.36266\n",
      "[10]\tvalidation_0-logloss:0.36050\n",
      "[11]\tvalidation_0-logloss:0.35886\n",
      "[12]\tvalidation_0-logloss:0.35595\n",
      "[13]\tvalidation_0-logloss:0.35565\n",
      "[14]\tvalidation_0-logloss:0.35449\n",
      "[15]\tvalidation_0-logloss:0.35264\n",
      "[16]\tvalidation_0-logloss:0.34927\n",
      "[17]\tvalidation_0-logloss:0.34896\n",
      "[18]\tvalidation_0-logloss:0.34998\n",
      "[19]\tvalidation_0-logloss:0.35107\n",
      "[20]\tvalidation_0-logloss:0.35079\n",
      "[21]\tvalidation_0-logloss:0.34884\n",
      "[22]\tvalidation_0-logloss:0.34836\n",
      "[23]\tvalidation_0-logloss:0.34841\n",
      "[24]\tvalidation_0-logloss:0.34909\n",
      "[25]\tvalidation_0-logloss:0.34939\n",
      "[26]\tvalidation_0-logloss:0.35071\n",
      "[27]\tvalidation_0-logloss:0.34858\n",
      "[28]\tvalidation_0-logloss:0.34985\n",
      "[29]\tvalidation_0-logloss:0.34939\n",
      "[30]\tvalidation_0-logloss:0.35099\n",
      "[31]\tvalidation_0-logloss:0.34984\n",
      "[32]\tvalidation_0-logloss:0.34979\n",
      "Stopping. Best iteration:\n",
      "[22]\tvalidation_0-logloss:0.34836\n",
      "\n",
      "84.66666666666667\n",
      "NS:Intuition(N)-Sensing(S) ....\n",
      "[0]\tvalidation_0-logloss:0.52669\n",
      "Will train until validation_0-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.43587\n",
      "[2]\tvalidation_0-logloss:0.37952\n",
      "[3]\tvalidation_0-logloss:0.34242\n",
      "[4]\tvalidation_0-logloss:0.31881\n",
      "[5]\tvalidation_0-logloss:0.30206\n",
      "[6]\tvalidation_0-logloss:0.28657\n",
      "[7]\tvalidation_0-logloss:0.27826\n",
      "[8]\tvalidation_0-logloss:0.27292\n",
      "[9]\tvalidation_0-logloss:0.26512\n",
      "[10]\tvalidation_0-logloss:0.26353\n",
      "[11]\tvalidation_0-logloss:0.25927\n",
      "[12]\tvalidation_0-logloss:0.25637\n",
      "[13]\tvalidation_0-logloss:0.25786\n",
      "[14]\tvalidation_0-logloss:0.25874\n",
      "[15]\tvalidation_0-logloss:0.25764\n",
      "[16]\tvalidation_0-logloss:0.25665\n",
      "[17]\tvalidation_0-logloss:0.25705\n",
      "[18]\tvalidation_0-logloss:0.25688\n",
      "[19]\tvalidation_0-logloss:0.25524\n",
      "[20]\tvalidation_0-logloss:0.25583\n",
      "[21]\tvalidation_0-logloss:0.25561\n",
      "[22]\tvalidation_0-logloss:0.25507\n",
      "[23]\tvalidation_0-logloss:0.25369\n",
      "[24]\tvalidation_0-logloss:0.25619\n",
      "[25]\tvalidation_0-logloss:0.25620\n",
      "[26]\tvalidation_0-logloss:0.25808\n",
      "[27]\tvalidation_0-logloss:0.25736\n",
      "[28]\tvalidation_0-logloss:0.25762\n",
      "[29]\tvalidation_0-logloss:0.25894\n",
      "[30]\tvalidation_0-logloss:0.25925\n",
      "[31]\tvalidation_0-logloss:0.25959\n",
      "[32]\tvalidation_0-logloss:0.26043\n",
      "[33]\tvalidation_0-logloss:0.26345\n",
      "Stopping. Best iteration:\n",
      "[23]\tvalidation_0-logloss:0.25369\n",
      "\n",
      "90.06060606060606\n",
      "FT:Feeling(F)-Thinking(T) ....\n",
      "[0]\tvalidation_0-logloss:0.59635\n",
      "Will train until validation_0-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.54727\n",
      "[2]\tvalidation_0-logloss:0.51216\n",
      "[3]\tvalidation_0-logloss:0.48908\n",
      "[4]\tvalidation_0-logloss:0.46987\n",
      "[5]\tvalidation_0-logloss:0.45139\n",
      "[6]\tvalidation_0-logloss:0.43880\n",
      "[7]\tvalidation_0-logloss:0.43102\n",
      "[8]\tvalidation_0-logloss:0.42246\n",
      "[9]\tvalidation_0-logloss:0.41375\n",
      "[10]\tvalidation_0-logloss:0.41081\n",
      "[11]\tvalidation_0-logloss:0.40493\n",
      "[12]\tvalidation_0-logloss:0.39995\n",
      "[13]\tvalidation_0-logloss:0.39888\n",
      "[14]\tvalidation_0-logloss:0.39470\n",
      "[15]\tvalidation_0-logloss:0.39104\n",
      "[16]\tvalidation_0-logloss:0.38879\n",
      "[17]\tvalidation_0-logloss:0.38719\n",
      "[18]\tvalidation_0-logloss:0.38428\n",
      "[19]\tvalidation_0-logloss:0.38233\n",
      "[20]\tvalidation_0-logloss:0.38192\n",
      "[21]\tvalidation_0-logloss:0.37802\n",
      "[22]\tvalidation_0-logloss:0.37713\n",
      "[23]\tvalidation_0-logloss:0.37706\n",
      "[24]\tvalidation_0-logloss:0.37589\n",
      "[25]\tvalidation_0-logloss:0.37437\n",
      "[26]\tvalidation_0-logloss:0.37183\n",
      "[27]\tvalidation_0-logloss:0.37242\n",
      "[28]\tvalidation_0-logloss:0.37097\n",
      "[29]\tvalidation_0-logloss:0.37047\n",
      "[30]\tvalidation_0-logloss:0.36842\n",
      "[31]\tvalidation_0-logloss:0.37165\n",
      "[32]\tvalidation_0-logloss:0.37130\n",
      "[33]\tvalidation_0-logloss:0.37106\n",
      "[34]\tvalidation_0-logloss:0.37105\n",
      "[35]\tvalidation_0-logloss:0.37188\n",
      "[36]\tvalidation_0-logloss:0.37080\n",
      "[37]\tvalidation_0-logloss:0.37254\n",
      "[38]\tvalidation_0-logloss:0.37064\n",
      "[39]\tvalidation_0-logloss:0.37117\n",
      "[40]\tvalidation_0-logloss:0.37027\n",
      "Stopping. Best iteration:\n",
      "[30]\tvalidation_0-logloss:0.36842\n",
      "\n",
      "84.06060606060606\n",
      "JP:Judging(J)-Perceiving(P) ....\n",
      "[0]\tvalidation_0-logloss:0.61598\n",
      "Will train until validation_0-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.57350\n",
      "[2]\tvalidation_0-logloss:0.54665\n",
      "[3]\tvalidation_0-logloss:0.52665\n",
      "[4]\tvalidation_0-logloss:0.51186\n",
      "[5]\tvalidation_0-logloss:0.50336\n",
      "[6]\tvalidation_0-logloss:0.49684\n",
      "[7]\tvalidation_0-logloss:0.49404\n",
      "[8]\tvalidation_0-logloss:0.48539\n",
      "[9]\tvalidation_0-logloss:0.48216\n",
      "[10]\tvalidation_0-logloss:0.47606\n",
      "[11]\tvalidation_0-logloss:0.47610\n",
      "[12]\tvalidation_0-logloss:0.47544\n",
      "[13]\tvalidation_0-logloss:0.47459\n",
      "[14]\tvalidation_0-logloss:0.47704\n",
      "[15]\tvalidation_0-logloss:0.47432\n",
      "[16]\tvalidation_0-logloss:0.47494\n",
      "[17]\tvalidation_0-logloss:0.47624\n",
      "[18]\tvalidation_0-logloss:0.47556\n",
      "[19]\tvalidation_0-logloss:0.47580\n",
      "[20]\tvalidation_0-logloss:0.47702\n",
      "[21]\tvalidation_0-logloss:0.47685\n",
      "[22]\tvalidation_0-logloss:0.47641\n",
      "[23]\tvalidation_0-logloss:0.47487\n",
      "[24]\tvalidation_0-logloss:0.47565\n",
      "[25]\tvalidation_0-logloss:0.47588\n",
      "Stopping. Best iteration:\n",
      "[15]\tvalidation_0-logloss:0.47432\n",
      "\n",
      "78.06060606060606\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(type_indicators)):\n",
    "    print(type_indicators[l],'....')\n",
    "    Y=list_personality[:,l]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.33,random_state=42)\n",
    "    model=XGBClassifier()\n",
    "    eval_set=[(x_test,y_test)]\n",
    "    model.fit(x_train,y_train,early_stopping_rounds=10,eval_metric=\"logloss\",eval_set=eval_set,verbose=True)\n",
    "    y_pred=model.predict(x_test)\n",
    "    predictions=[round(value) for value in y_pred]\n",
    "    accuracy=accuracy_score(y_test,predictions)\n",
    "    print(accuracy*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a slight variation in the accuracy scores between the two models.\n",
    "Next, we will bring in our tweets obtained using RapidMiner to test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=pd.read_csv('C:\\\\Users\\\\Akshita Puri\\\\Desktop\\\\project\\\\dmpa\\\\TomCruise_cleanedT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Summer #TopGun https AABKxnEDv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Warning Real flying Real forces make puke #Top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>#TopGun https vdhTtXb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Feel need Trailer tomorrow #TopGun https rWHfK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Thank fans came Hall today great share first t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text\n",
       "0   0                     Summer #TopGun https AABKxnEDv\n",
       "1   1  Warning Real flying Real forces make puke #Top...\n",
       "2   2                              #TopGun https vdhTtXb\n",
       "3   3  Feel need Trailer tomorrow #TopGun https rWHfK...\n",
       "4   4  Thank fans came Hall today great share first t..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=' '.join(tweets.Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, an initial value needs to be assigned for XGBoost to form a tree. This initial value keeps getting corrected as the model proceeds while creating trees. Hence, we have assigned any random personality type to the user tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_t=pd.DataFrame(data={'type':'INFJ','posts':[tweet]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets will also require data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet,dummy=pre_process(final_t,remove_stop_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also find the contextual words in tweets to compare with our training set and that is the basis for tree formation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x_cnt=counter.transform(tweet)\n",
    "\n",
    "t_x_tfidf=tf.transform(t_x_cnt).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE:Introversion(I)/Extroversion(E) ....\n",
      "NS:Intuition(N)-Sensing(S) ....\n",
      "FT:Feeling(F)-Thinking(T) ....\n",
      "JP:Judging(J)-Perceiving(P) ....\n"
     ]
    }
   ],
   "source": [
    "param={}\n",
    "param['n_parameters']=200\n",
    "param['max_depth']=2\n",
    "param['n_thread']=8\n",
    "param['learning_rate']=0.2\n",
    "\n",
    "result=[]\n",
    "for l in range(len(type_indicators)):\n",
    "    print(type_indicators[l],'....')\n",
    "    Y=list_personality[:,l]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.33,random_state=42)\n",
    "    model=XGBClassifier(**param)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(t_x_tfidf)\n",
    "    result.append(y_pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INFP'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_back(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
